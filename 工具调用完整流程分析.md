# LibreChat 工具调用完整流程分析

本文档详细分析了 LibreChat 系统中从前端用户输入到最终返回给用户的完整工具调用流程。

## 目录

1. [流程概览](#流程概览)
2. [阶段一：前端用户输入](#阶段一前端用户输入)
3. [阶段二：后端接收请求](#阶段二后端接收请求)
4. [阶段三：加载工具列表](#阶段三加载工具列表)
5. [阶段四：LLM分析意图](#阶段四llm分析意图)
6. [阶段五：LLM调用工具](#阶段五llm调用工具)
7. [阶段六：获取工具结果](#阶段六获取工具结果)
8. [阶段七：LLM总结返回](#阶段七llm总结返回)
9. [阶段八：流式返回前端](#阶段八流式返回前端)

---

## 流程概览

```
┌─────────────────┐
│  前端用户输入     │
│  "帮我生成图片"   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  后端接收请求     │
│  AgentController │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  加载工具列表     │
│  loadAgentTools │
│  - MCP工具       │
│  - FunctionTool │
│  - Actions      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  LLM分析意图     │
│  formatMessages  │
│  传递工具定义     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  LLM决定调用工具  │
│  createRun      │
│  processStream  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  执行工具调用     │
│  processRequired │
│  Actions        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  获取工具结果     │
│  tool._call()    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  LLM总结返回     │
│  生成最终回复     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  流式返回前端     │
│  SSE Stream      │
└─────────────────┘
```

---

## 阶段一：前端用户输入

### 1.1 用户输入处理

**文件：`client/src/hooks/Chat/useChatFunctions.ts`**

```typescript
// 第 75-93 行：ask 函数处理用户输入
const ask: TAskFunction = (
  {
    text,
    overrideConvoId,
    overrideUserMessageId,
    parentMessageId = null,
    conversationId = null,
    messageId = null,
  },
  {
    editedContent = null,
    editedMessageId = null,
    isRegenerate = false,
    isContinued = false,
    isEdited = false,
    overrideMessages,
    overrideFiles,
  } = {},
) => {
  // 1. 验证输入
  if (!!isSubmitting || text === '') {
    return;
  }

  // 2. 获取对话配置
  const conversation = cloneDeep(immutableConversation);
  const endpoint = conversation?.endpoint;

  // 3. 构建消息对象
  const intermediateId = overrideUserMessageId ?? v4();
  parentMessageId = parentMessageId ?? latestMessage?.messageId ?? Constants.NO_PARENT;

  // 4. 发送请求到后端
  // ...
};
```

**关键点：**
- 用户输入通过 `ask` 函数处理
- 生成唯一的 `messageId` 和 `parentMessageId`
- 构建包含对话上下文的请求对象

---

## 阶段二：后端接收请求

### 2.1 请求控制器

**文件：`api/server/controllers/agents/request.js`**

```javascript
// 第 31-248 行：AgentController 主函数
const AgentController = async (req, res, next, initializeClient, addTitle) => {
  let {
    text,
    isRegenerate,
    endpointOption,
    conversationId,
    isContinued = false,
    editedContent = null,
    parentMessageId = null,
    overrideParentMessageId = null,
    responseMessageId: editedResponseMessageId = null,
  } = req.body;

  // 1. 初始化客户端
  const result = await initializeClient({
    req,
    res,
    endpointOption,
    conversationId,
  });

  const { client, ...rest } = result;

  // 2. 配置消息选项
  const messageOptions = {
    user: userId,
    onStart,
    getReqData,
    isContinued,
    isRegenerate,
    editedContent,
    conversationId,
    parentMessageId,
    abortController,
    overrideParentMessageId,
    isEdited: !!editedContent,
    userMCPAuthMap: result.userMCPAuthMap,
    responseMessageId: editedResponseMessageId,
    progressOptions: {
      res,
    },
  };

  // 3. 发送消息到客户端处理
  let response = await client.sendMessage(text, messageOptions);
};
```

**关键点：**
- 接收前端请求并解析参数
- 初始化客户端（AgentClient）
- 配置消息处理选项
- 调用 `client.sendMessage()` 开始处理流程

---

## 阶段三：加载工具列表

### 3.1 工具加载入口

**文件：`api/server/services/ToolService.js`**

```javascript
// 第 372-458 行：loadAgentTools 函数
async function loadAgentTools({ req, res, agent, signal, tool_resources, openAIApiKey }) {
  // 1. 检查工具配置
  if (!agent.tools || agent.tools.length === 0) {
    return {};
  }

  // 2. 检查能力权限
  const enabledCapabilities = new Set(
    endpointsConfig?.[EModelEndpoint.agents]?.capabilities ?? []
  );
  const areToolsEnabled = checkCapability(AgentCapabilities.tools);

  // 3. 过滤可用工具
  const _agentTools = agent.tools?.filter((tool) => {
    if (tool === Tools.file_search) {
      return checkCapability(AgentCapabilities.file_search);
    } else if (tool === Tools.execute_code) {
      return checkCapability(AgentCapabilities.execute_code);
    } else if (tool === Tools.web_search) {
      return checkCapability(AgentCapabilities.web_search);
    }
    return true;
  });

  // 4. 加载工具实例
  const { loadedTools, toolContextMap } = await loadTools({
    agent,
    signal,
    userMCPAuthMap,
    functions: true,
    user: req.user.id,
    tools: _agentTools,
    options: {
      req,
      res,
      openAIApiKey,
      tool_resources,
      processFileURL,
      uploadImageBuffer,
      returnMetadata: true,
    },
    webSearch: appConfig.webSearch,
    fileStrategy: appConfig.fileStrategy,
    imageOutputType: appConfig.imageOutputType,
  });

  // 5. 格式化工具为 LLM 可用的格式
  const agentTools = [];
  for (let i = 0; i < loadedTools.length; i++) {
    const tool = loadedTools[i];
    
    if (tool instanceof DynamicStructuredTool) {
      agentTools.push(tool);
      continue;
    }

    const toolDefinition = {
      name: tool.name,
      schema: tool.schema,
      description: tool.description,
    };

    if (imageGenTools.has(tool.name)) {
      toolDefinition.responseFormat = 'content_and_artifact';
    }

    const toolInstance = toolFn(async (...args) => {
      return tool['_call'](...args);
    }, toolDefinition);

    agentTools.push(toolInstance);
  }

  return {
    tools: agentTools,
    toolContextMap,
    userMCPAuthMap,
  };
}
```

### 3.2 工具加载实现

**文件：`api/app/clients/tools/util/handleTools.js`**

```javascript
// 第 160-489 行：loadTools 函数
const loadTools = async ({
  user,
  agent,
  model,
  signal,
  endpoint,
  userMCPAuthMap,
  tools = [],
  options = {},
  functions = true,
  returnMap = false,
  webSearch,
  fileStrategy,
  imageOutputType,
}) => {
  // 1. 定义工具构造函数映射
  const toolConstructors = {
    flux: FluxAPI,
    calculator: Calculator,
    google: GoogleSearchAPI,
    baidu_search: BaiduSearchAPI,
    open_weather: OpenWeather,
    wolfram: StructuredWolfram,
    'stable-diffusion': StructuredSD,
    'azure-ai-search': StructuredACS,
    traversaal_search: TraversaalSearch,
    tavily_search_results_json: TavilySearchResults,
  };

  // 2. 处理特殊工具（需要异步初始化）
  const customConstructors = {
    youtube: async (_toolContextMap) => {
      const authFields = getAuthFields('youtube');
      const authValues = await loadAuthValues({ userId: user, authFields });
      return createYouTubeTools(authValues);
    },
    modelscope_qwen_image: async () => {
      const authFields = getAuthFields('modelscope_qwen_image');
      const authValues = await loadAuthValues({ userId: user, authFields });
      return createModelScopeQwenImageTools({
        ...authValues,
        isAgent: !!agent,
        req: options.req,
      });
    },
  };

  // 3. 处理 MCP 工具
  for (const tool of tools) {
    if (tool && mcpToolPattern.test(tool)) {
      const [toolName, serverName] = tool.split(Constants.mcp_delimiter);
      
      if (toolName === Constants.mcp_all) {
        requestedMCPTools[serverName] = [
          {
            type: 'all',
            serverName,
          },
        ];
        continue;
      }

      requestedMCPTools[serverName] = requestedMCPTools[serverName] || [];
      requestedMCPTools[serverName].push({
        type: 'single',
        toolKey: tool,
        serverName,
      });
    }
  }

  // 4. 加载所有工具实例
  const toolPromises = [];
  for (const tool of tools) {
    const validTool = requestedTools[tool];
    if (validTool) {
      toolPromises.push(
        validTool().catch((error) => {
          logger.error(`Error loading tool ${tool}:`, error);
          return null;
        }),
      );
    }
  }

  const loadedTools = (await Promise.all(toolPromises)).flatMap((plugin) => plugin || []);

  // 5. 加载 MCP 工具
  for (const [serverName, toolConfigs] of Object.entries(requestedMCPTools)) {
    const mcpParams = {
      index,
      signal,
      user: safeUser,
      userMCPAuthMap,
      res: options.res,
      model: agent?.model ?? model,
      serverName: config.serverName,
      provider: agent?.provider ?? endpoint,
    };

    const mcpTool = await createMCPTools(mcpParams);
    if (Array.isArray(mcpTool)) {
      loadedTools.push(...mcpTool);
    } else if (mcpTool) {
      loadedTools.push(mcpTool);
    }
  }

  return { loadedTools, toolContextMap };
};
```

**关键点：**
- 根据工具名称加载对应的工具类
- 处理需要认证的工具（加载认证信息）
- 处理 MCP 工具（Model Context Protocol）
- 处理 Actions（自定义 OpenAPI 工具）
- 返回格式化的工具列表供 LLM 使用

---

## 阶段四：LLM分析意图

### 4.1 消息格式化

**文件：`api/app/clients/prompts/formatMessages.js`**

```javascript
// 第 141-238 行：formatAgentMessages 函数
const formatAgentMessages = (payload) => {
  const messages = [];

  for (const message of payload) {
    // 1. 处理用户消息
    if (message.role !== 'assistant') {
      messages.push(formatMessage({ message, langChain: true }));
      continue;
    }

    // 2. 处理助手消息（包含工具调用历史）
    let currentContent = [];
    let lastAIMessage = null;

    for (const part of message.content) {
      if (part.type === ContentTypes.TEXT && part.tool_call_ids) {
        // 创建包含工具调用的 AIMessage
        lastAIMessage = new AIMessage({
          content: part.text || '',
        });
        messages.push(lastAIMessage);
      } else if (part.type === ContentTypes.TOOL_CALL) {
        // 添加工具调用到 AIMessage
        const { output, args: _args, ...tool_call } = part.tool_call;
        let args = _args;
        try {
          args = JSON.parse(_args);
        } catch (e) {
          if (typeof _args === 'string') {
            args = { input: _args };
          }
        }

        tool_call.args = args;
        lastAIMessage.tool_calls.push(tool_call);

        // 添加对应的 ToolMessage（工具执行结果）
        messages.push(
          new ToolMessage({
            tool_call_id: tool_call.id,
            name: tool_call.name,
            content: output || '',
          }),
        );
      }
    }
  }

  return messages;
};
```

### 4.2 发送给 LLM

**文件：`api/server/controllers/agents/client.js`**

```javascript
// 第 848-978 行：chatCompletion 函数
async chatCompletion({ payload, userMCPAuthMap, abortController = null }) {
  // 1. 配置运行参数
  config = {
    runName: 'AgentRun',
    configurable: {
      thread_id: this.conversationId,
      last_agent_index: this.agentConfigs?.size ?? 0,
      user_id: this.user ?? this.options.req.user?.id,
      requestBody: {
        messageId: this.responseMessageId,
        conversationId: this.conversationId,
        parentMessageId: this.parentMessageId,
      },
      user: createSafeUser(this.options.req.user),
    },
    recursionLimit: agentsEConfig?.recursionLimit ?? 25,
    signal: abortController.signal,
    streamMode: 'values',
    version: 'v2',
  };

  // 2. 格式化消息为 LangChain 格式
  const toolSet = new Set((this.options.agent.tools ?? []).map((tool) => tool && tool.name));
  let { messages: initialMessages, indexTokenCountMap } = formatAgentMessages(
    payload,
    this.indexTokenCountMap,
    toolSet,
  );

  // 3. 创建运行实例并处理流
  const runAgents = async (messages) => {
    const agents = [this.options.agent];
    
    run = await createRun({
      agents,
      indexTokenCountMap,
      runId: this.responseMessageId,
      signal: abortController.signal,
      customHandlers: this.options.eventHandlers,
      requestBody: config.configurable.requestBody,
      user: createSafeUser(this.options.req?.user),
      tokenCounter: createTokenCounter(this.getEncoding()),
    });

    // 4. 处理流（LLM 会在这里分析意图并决定调用工具）
    await run.processStream({ messages }, config, {
      callbacks: {
        [Callback.TOOL_ERROR]: logToolError,
      },
    });
  };

  await runAgents(initialMessages);
}
```

**关键点：**
- 将消息历史格式化为 LangChain 消息格式
- 包含工具定义（schema、description）供 LLM 分析
- LLM 根据用户意图和可用工具列表决定调用哪些工具
- 通过 `createRun` 和 `processStream` 启动 LLM 推理流程

---

## 阶段五：LLM调用工具

### 5.1 LLM 生成工具调用

当 LLM 分析完用户意图后，会生成工具调用请求。这些请求通过 LangGraph 的事件系统传递。

**文件：`api/server/services/AssistantService.js`**

```javascript
// 第 345-454 行：runAssistant 函数（Assistants API 模式）
async function runAssistant({
  openai,
  run_id,
  thread_id,
  accumulatedSteps = [],
  accumulatedMessages = [],
  in_progress: inProgress,
}) {
  // 1. 等待运行完成或需要工具调用
  const run = await waitForRun({
    openai,
    run_id,
    thread_id,
    runManager,
    pollIntervalMs,
    timeout: timeoutMs,
  });

  // 2. 检查是否需要工具调用
  if (!run.required_action) {
    // 没有工具调用，直接返回结果
    return {
      run,
      steps,
      messages: sortedMessages,
      finalMessage: openai.responseMessage,
      text: openai.responseText,
    };
  }

  // 3. 解析工具调用请求
  const { submit_tool_outputs } = run.required_action;
  const actions = submit_tool_outputs.tool_calls.map((item) => {
    const functionCall = item.function;
    const args = JSON.parse(functionCall.arguments);
    return {
      tool: functionCall.name,
      toolInput: args,
      toolCallId: item.id,
      run_id,
      thread_id,
    };
  });

  // 4. 处理工具调用
  const tool_outputs = await processRequiredActions(openai, actions);
  
  // 5. 提交工具输出给 LLM
  const toolRun = await openai.beta.threads.runs.submitToolOutputs(run.id, {
    thread_id: run.thread_id,
    tool_outputs,
  });

  // 6. 递归调用，等待 LLM 处理工具结果
  return await runAssistant({
    openai,
    run_id: toolRun.id,
    thread_id,
    accumulatedSteps: steps,
    accumulatedMessages: messages,
    in_progress,
  });
}
```

### 5.2 处理工具调用请求

**文件：`api/server/services/ToolService.js`**

```javascript
// 第 76-360 行：processRequiredActions 函数
async function processRequiredActions(client, requiredActions) {
  // 1. 加载工具定义
  const toolDefinitions = await getCachedTools();
  const tools = requiredActions
    .map((action) => action.tool)
    .filter((toolName) => !!toolName);

  // 2. 加载工具实例
  const { loadedTools } = await loadTools({
    user: client.req.user.id,
    model: client.req.body.model ?? 'gpt-4o-mini',
    tools,
    functions: true,
    endpoint: client.req.body.endpoint,
    options: {
      processFileURL,
      req: client.req,
      uploadImageBuffer,
      openAIApiKey: client.apiKey,
      returnMetadata: true,
    },
    webSearch: appConfig.webSearch,
    fileStrategy: appConfig.fileStrategy,
    imageOutputType: appConfig.imageOutputType,
  });

  // 3. 创建工具映射
  const ToolMap = loadedTools.reduce((map, tool) => {
    map[tool.name] = tool;
    return map;
  }, {});

  // 4. 处理每个工具调用
  const promises = [];
  for (let i = 0; i < requiredActions.length; i++) {
    const currentAction = requiredActions[i];
    let tool = ToolMap[currentAction.tool] ?? ActionToolMap[currentAction.tool];

    // 5. 处理工具输出
    const handleToolOutput = async (output) => {
      requiredActions[i].output = output;

      const toolCall = {
        function: {
          name: currentAction.tool,
          arguments: JSON.stringify(currentAction.toolInput),
          output,
        },
        id: currentAction.toolCallId,
        type: 'function',
        progress: 1,
        action: isActionTool,
      };

      // 6. 流式发送工具调用结果到前端
      client.addContentData({
        [ContentTypes.TOOL_CALL]: toolCall,
        index: toolCallIndex,
        type: ContentTypes.TOOL_CALL,
      });

      return {
        tool_call_id: currentAction.toolCallId,
        output,
      };
    };

    // 7. 执行工具调用
    try {
      const promise = tool
        ._call(currentAction.toolInput)
        .then(handleToolOutput)
        .catch(handleToolError);
      promises.push(promise);
    } catch (error) {
      const toolOutputError = handleToolError(error);
      promises.push(Promise.resolve(toolOutputError));
    }
  }

  // 8. 等待所有工具调用完成
  return {
    tool_outputs: await Promise.all(promises),
  };
}
```

**关键点：**
- LLM 生成工具调用请求（包含工具名称和参数）
- 系统根据工具名称加载对应的工具实例
- 并行执行所有工具调用
- 实时流式发送工具调用状态到前端

---

## 阶段六：获取工具结果

### 6.1 工具执行

工具的实际执行逻辑在各自的工具类中实现。以图片生成工具为例：

**文件：`api/app/clients/tools/structured/ModelScopeQwenImage.js`**

```javascript
// 工具执行函数（简化版）
const imageGenTool = tool(
  async ({ prompt, parameters = {}, model: overrideModel }, runnableConfig) => {
    // 1. 提交生成任务
    const generationResponse = await submitGeneration({
      baseURL,
      apiKey,
      payload: { model, prompt: prompt.trim(), ...parameters },
      timeoutMs,
      signal,
    });

    // 2. 轮询任务状态
    const taskResult = await pollForResult({
      baseURL,
      apiKey,
      taskId: generationResponse.task_id,
      timeoutMs,
      signal,
    });

    // 3. 获取图片 URL
    const imageUrl = resolveImageUrl(taskResult.output_images[0]);

    // 4. 下载图片并转换为 base64
    const { base64: base64Image, contentType } = await fetchBase64(
      imageUrl,
      signal,
      timeoutMs
    );

    // 5. 返回 content_and_artifact 格式
    const file_ids = [v4()];
    return {
      content: `Image generated successfully. File ID: ${file_ids[0]}`,
      artifact: {
        files: [
          {
            id: file_ids[0],
            name: 'generated_image.png',
            data: base64Image,
            mimeType: contentType,
          },
        ],
      },
    };
  },
  {
    name: 'modelscope_qwen_image',
    description: 'Generate images using ModelScope Qwen Image model',
    schema: zodSchema,
  }
);
```

### 6.2 MCP 工具调用

**文件：`packages/api/src/mcp/MCPManager.ts`**

```typescript
// 第 164-256 行：callTool 方法
async callTool({
  user,
  serverName,
  toolName,
  provider,
  toolArguments,
  options,
  tokenMethods,
  requestBody,
  flowManager,
  oauthStart,
  oauthEnd,
  customUserVars,
}): Promise<t.FormattedToolResponse> {
  // 1. 获取 MCP 连接
  connection = await this.getConnection({
    serverName,
    user,
    flowManager,
    tokenMethods,
    oauthStart,
    oauthEnd,
    signal: options?.signal,
    customUserVars,
    requestBody,
  });

  // 2. 检查连接状态
  if (!(await connection.isConnected())) {
    throw new McpError(
      ErrorCode.InternalError,
      `Connection is not active. Cannot execute tool ${toolName}.`
    );
  }

  // 3. 调用 MCP 工具
  const result = await connection.client.request(
    {
      method: 'tools/call',
      params: {
        name: toolName,
        arguments: toolArguments,
      },
    },
    CallToolResultSchema,
    {
      timeout: connection.timeout,
      resetTimeoutOnProgress: true,
      ...options,
    },
  );

  // 4. 格式化返回结果
  return formatToolContent(result as t.MCPToolCallResponse, provider);
}
```

**关键点：**
- 不同类型的工具有不同的执行逻辑
- 图片生成工具返回 `content_and_artifact` 格式
- MCP 工具通过 MCP 协议调用外部服务
- Actions 工具通过 OpenAPI 规范调用 REST API
- 所有工具结果都会返回给 `processRequiredActions` 函数

---

## 阶段七：LLM总结返回

### 7.1 提交工具结果给 LLM

工具执行完成后，结果会提交回 LLM，LLM 根据工具结果生成最终回复。

**文件：`api/server/services/AssistantService.js`**

```javascript
// 第 426-443 行：提交工具输出
const { submit_tool_outputs } = run.required_action;
const actions = submit_tool_outputs.tool_calls.map((item) => {
  const functionCall = item.function;
  const args = JSON.parse(functionCall.arguments);
  return {
    tool: functionCall.name,
    toolInput: args,
    toolCallId: item.id,
    run_id,
    thread_id,
  };
});

// 处理工具调用并获取结果
const tool_outputs = await processRequiredActions(openai, actions);

// 提交工具输出给 LLM
const toolRun = await openai.beta.threads.runs.submitToolOutputs(run.id, {
  thread_id: run.thread_id,
  tool_outputs,
});

// 递归调用，LLM 会处理工具结果并生成最终回复
return await runAssistant({
  openai,
  run_id: toolRun.id,
  thread_id,
  accumulatedSteps: steps,
  accumulatedMessages: messages,
  in_progress,
});
```

### 7.2 处理最终消息

**文件：`api/server/services/AssistantService.js`**

```javascript
// 第 170-331 行：createInProgressHandler 函数
function createInProgressHandler(openai, thread_id, messages) {
  async function in_progress({ step }) {
    if (step.type === StepTypes.MESSAGE_CREATION && step.status === StepStatus.COMPLETED) {
      const { message_id } = step.step_details.message_creation;
      
      // 1. 获取消息
      const message = await openai.beta.threads.messages.retrieve(message_id, { thread_id });
      if (!message?.content?.length) {
        return;
      }
      messages.push(message);

      // 2. 处理消息内容
      const result = await processMessages({ openai, client: openai, messages: [message] });
      
      // 3. 添加文本内容到响应
      openai.addContentData({
        [ContentTypes.TEXT]: { value: result.text },
        type: ContentTypes.TEXT,
        index: messageIndex,
      });

      // 4. 创建流式输出
      const { onProgress: progressCallback } = createOnProgress({});
      const onProgress = progressCallback({
        res: openai.res,
        index: messageIndex,
        messageId: openai.responseMessage.messageId,
        conversationId: openai.responseMessage.conversationId,
        type: ContentTypes.TEXT,
        thread_id,
      });

      // 5. 流式发送文本
      await sleep(500);
      const stream = new TextStream(result.text, { delay: 9 });
      await stream.processTextStream(onProgress);
    }
  }

  return in_progress;
}
```

**关键点：**
- 工具结果提交给 LLM 后，LLM 会分析结果并生成最终回复
- 最终回复通过 `processMessages` 处理
- 使用 `TextStream` 流式发送文本内容到前端
- 支持多轮工具调用（LLM 可能根据结果再次调用工具）

---

## 阶段八：流式返回前端

### 8.1 服务端流式发送

**文件：`api/server/services/AssistantService.js`**

```javascript
// 第 50-71 行：addContentData 方法
openai.addContentData = (data) => {
  const { type, index } = data;
  openai.responseMessage.content[index] = { type, [type]: data[type] };

  if (type === ContentTypes.TEXT) {
    openai.responseText += data[type].value;
    return;
  }

  // 发送非文本内容（工具调用、图片等）
  const contentData = {
    index,
    type,
    [type]: data[type],
    messageId,
    thread_id,
    conversationId,
  };

  logger.debug('Content data:', contentData);
  sendEvent(openai.res, contentData);
};
```

### 8.2 前端接收 SSE 事件

**文件：`client/src/hooks/SSE/useSSE.ts`**

```typescript
// 第 121-169 行：SSE 消息处理
sse.addEventListener('message', (e: MessageEvent) => {
  const data = JSON.parse(e.data);

  if (data.final != null) {
    // 最终消息
    clearDraft(submission.conversation?.conversationId);
    const { plugins } = data;
    finalHandler(data, { ...submission, plugins } as EventSubmission);
    return;
  } else if (data.created != null) {
    // 消息创建事件
    const runId = v4();
    setActiveRunId(runId);
    userMessage = {
      ...userMessage,
      ...data.message,
      overrideParentMessageId: userMessage.overrideParentMessageId,
    };
    createdHandler(data, { ...submission, userMessage } as EventSubmission);
  } else if (data.event != null) {
    // 工具调用等事件
    stepHandler(data, { ...submission, userMessage } as EventSubmission);
  } else if (data.type != null) {
    // 内容更新（文本、图片等）
    const { text, index } = data;
    if (text != null && index !== textIndex) {
      textIndex = index;
    }
    contentHandler({ data, submission: submission as EventSubmission });
  }
});
```

### 8.3 前端更新 UI

**文件：`client/src/hooks/SSE/useStepHandler.ts`**

```typescript
// 第 197-448 行：stepHandler 函数
const stepHandler = useCallback(
  ({ event, data }: TStepEvent, submission: EventSubmission) => {
    const messages = getMessages() || [];

    if (event === 'on_run_step') {
      // 处理工具调用步骤
      const { stepDetails } = data as unknown as { stepDetails: Agents.StepDetails };
      
      if (stepDetails.type === StepTypes.TOOL_CALLS) {
        const { tool_calls } = stepDetails;
        
        for (const toolCall of tool_calls) {
          const contentPart: Agents.MessageContentComplex = {
            type: ContentTypes.TOOL_CALL,
            tool_call: toolCall,
          };

          // 更新消息内容
          updatedResponse = updateContent(updatedResponse, currentIndex, contentPart, true);
        }
      }
    } else if (event === 'on_run_step_completed') {
      // 工具调用完成
      const { result } = data as unknown as { result: Agents.ToolEndEvent };
      const contentPart: Agents.MessageContentComplex = {
        type: ContentTypes.TOOL_CALL,
        tool_call: result.tool_call,
      };

      updatedResponse = updateContent(updatedResponse, currentIndex, contentPart, true);
      setMessages(updatedMessages);
    }

    return () => {
      toolCallIdMap.current.clear();
      messageMap.current.clear();
      stepMap.current.clear();
    };
  },
  [getMessages, setIsSubmitting, setMessages],
);
```

**关键点：**
- 使用 Server-Sent Events (SSE) 实现流式传输
- 前端实时接收并更新 UI
- 支持多种内容类型：文本、工具调用、图片等
- 工具调用状态实时显示（进行中、完成、错误）

---

## 总结

完整的工具调用流程包括以下关键步骤：

1. **前端输入** → 用户输入消息，前端通过 `useChatFunctions` 发送请求到后端
2. **后端接收** → `AgentController` 接收请求，初始化 `AgentClient`，准备处理流程
3. **加载工具** → 通过 `loadAgentTools` 加载所有可用工具：
   - MCP 工具（通过 `createMCPTool` 创建）
   - FunctionTool（结构化工具，如计算器、搜索等）
   - Actions（自定义 OpenAPI 工具）
   - 系统工具（代码执行、文件搜索等）
4. **LLM分析意图** → 通过 `formatAgentMessages` 格式化消息为 LangChain 格式，包含工具定义和描述，发送给 LLM 进行分析
5. **LLM调用工具** → LLM 根据用户意图和可用工具列表，决定调用哪些工具，生成工具调用请求（包含工具名称和参数）
6. **执行工具调用** → 通过 `processRequiredActions` 处理工具调用：
   - 根据工具类型（MCP/FunctionTool/Action）选择对应的执行方式
   - 调用工具的 `_call` 方法执行实际功能
   - 处理工具执行过程中的错误和异常
7. **获取工具结果** → 工具执行完成后返回结果：
   - 文本结果直接返回
   - 图片生成工具返回 `content_and_artifact` 格式（包含文本描述和图片数据）
   - MCP 工具通过 `MCPManager.callTool` 获取结果
8. **LLM总结返回** → 将工具执行结果提交回 LLM：
   - 通过 `submitToolOutputs` 将结果发送给 LLM
   - LLM 根据工具结果生成最终的自然语言回复
   - 对于图片生成工具，LLM 会收到简化的文本描述，图片通过 artifact 单独处理
9. **流式返回前端** → 通过 Server-Sent Events (SSE) 实时流式传输：
   - 使用 `sendEvent` 发送各种事件（文本、工具调用、图片等）
   - 前端通过 `useSSE` 接收事件并更新 UI
   - 支持实时显示工具调用状态、文本流式输出、图片渲染等

### 关键技术点

- **工具定义传递**：所有工具的定义（名称、描述、参数 schema）都会传递给 LLM，让 LLM 了解可用工具
- **工具执行隔离**：不同类型的工具（MCP、FunctionTool、Actions）有独立的执行路径
- **结果格式化**：工具结果需要转换为 LLM 可理解的格式，同时保留原始数据用于前端展示
- **流式传输**：整个流程支持流式传输，用户可以实时看到 LLM 的思考和工具执行过程
- **错误处理**：每个阶段都有完善的错误处理机制，确保流程的健壮性
- **递归调用**：支持 LLM 多次调用工具，直到获得满意的结果（通过 `recursionLimit` 控制）

### 核心代码文件

- **前端**：`client/src/hooks/Chat/useChatFunctions.ts`、`client/src/hooks/SSE/useSSE.ts`
- **后端控制器**：`api/server/controllers/agents/request.js`、`api/server/controllers/agents/client.js`
- **工具服务**：`api/server/services/ToolService.js`、`api/app/clients/tools/util/handleTools.js`
- **消息格式化**：`api/app/clients/prompts/formatMessages.js`
- **流式处理**：`api/server/services/AssistantService.js`、`api/server/services/Runs/StreamRunManager.js`
- **MCP 工具**：`packages/api/src/mcp/MCPManager.ts`、`api/server/services/MCP.js`