# 智能体调用 Function Tool 完整流程分析

## 概述

本文档详细分析了 LibreChat 中智能体（Agent）调用 `modelscope_qwen_image` 工具生成图片的完整流程，包括：
1. 为什么会对用户提问进行优化
2. 工具如何被调用
3. 图片如何返回并显示给用户

---

## 一、为什么会对用户提问进行优化？

### 1.1 优化发生的原因

**用户提问的优化不是代码层面的处理，而是由 LLM（大语言模型）自动完成的。** 这是 LangChain Agent 框架的核心机制：

1. **工具描述驱动优化**
   - 工具定义在 `ModelScopeQwenImage.js` 中包含了详细的 `description` 和 `schema`
   - LLM 读取工具描述后，理解需要什么样的输入格式
   - 根据工具要求，LLM 会自动优化和翻译用户的原始请求

2. **工具 Schema 的影响**
   ```javascript
   // ModelScopeQwenImage.js 第 19-36 行
   schema: z.object({
     prompt: z
       .string()
       .max(32000)
       .describe(
         'Describe the desired scene in rich visual detail (subjects, lighting, composition, style, mood, background).',
       ),
   })
   ```
   - Schema 中的 `describe` 告诉 LLM：需要"丰富的视觉细节描述"
   - LLM 看到用户的中文请求后，会将其转换为更详细、更符合工具要求的英文 prompt

3. **智能体的系统指令**
   - 智能体可能有系统指令要求它优化用户输入
   - LLM 会根据上下文和工具要求，自动进行：
     - 语言翻译（中文 → 英文）
     - 内容增强（添加细节、风格描述等）
     - 格式优化（符合工具期望的格式）

### 1.2 优化流程示例

```
用户输入（中文）:
"帮我生成一张在夕阳西下的金色光辉中,一位年轻男子和一只金毛犬在沙滩上共享着亲密的时刻..."

↓ LLM 分析工具要求

优化后的 Prompt（英文）:
"A heartwarming scene at sunset on a beach, with golden sunlight casting warm hues across the scene. 
A young man and a golden retriever dog sitting together intimately on soft sand. 
They are sharing a tender moment, with the man gently petting the dog. 
The background shows a calm ocean with gentle waves lapping at the shore. 
The sky is painted in beautiful orange, pink and golden colors as the sun sets. 
The atmosphere is peaceful, warm and emotional. 
Photorealistic style, high detail, cinematic lighting, soft focus on the subjects."
```

---

## 二、工具调用完整流程

### 2.1 工具加载阶段

**文件：`api/app/clients/tools/util/handleTools.js`**

```javascript
// 第 222-230 行：加载 modelscope_qwen_image 工具
modelscope_qwen_image: async () => {
  const authFields = getAuthFields('modelscope_qwen_image');
  const authValues = await loadAuthValues({ userId: user, authFields });
  return createModelScopeQwenImageTools({
    ...authValues,
    isAgent: !!agent,
    req: options.req,
  });
}
```

**流程：**
1. 从配置中获取认证字段（`MODELSCOPE_API_KEY`）
2. 加载认证值
3. 调用 `createModelScopeQwenImageTools` 创建工具实例
4. 工具被注册到智能体的工具列表中

### 2.2 工具定义

**文件：`api/app/clients/tools/structured/ModelScopeQwenImage.js`**

**关键配置：**
```javascript
// 第 14-39 行：工具定义
const toolkit = {
  modelscope_qwen_image: {
    name: 'modelscope_qwen_image',
    description: 'Generate high-quality, photorealistic images using the Qwen-Image model hosted on ModelScope.',
    schema: z.object({
      prompt: z.string().max(32000).describe('Describe the desired scene in rich visual detail...'),
      // ...
    }),
    responseFormat: 'content_and_artifact',  // 关键：指定返回格式
  },
};
```

**`responseFormat: 'content_and_artifact'` 的作用：**
- 告诉 LangChain 这个工具返回两个部分：
  1. `content`: 文本响应（用于 LLM 理解）
  2. `artifact`: 二进制内容（图片数据）

### 2.3 智能体决策调用工具

**文件：`api/server/controllers/agents/client.js`**

```javascript
// 第 848-978 行：chatCompletion 方法
async chatCompletion({ payload, userMCPAuthMap, abortController = null }) {
  // 1. 格式化消息
  let { messages: initialMessages } = formatAgentMessages(
    payload,
    this.indexTokenCountMap,
    toolSet,
  );

  // 2. 创建运行实例
  run = await createRun({
    agents,
    // ...
  });

  // 3. 处理流
  await run.processStream({ messages }, config, {
    callbacks: {
      [Callback.TOOL_ERROR]: logToolError,
    },
  });
}
```

**流程：**
1. 用户消息被格式化为 LangChain 消息格式
2. 消息发送给 LLM（通过 LangGraph）
3. LLM 分析用户请求，决定需要调用 `modelscope_qwen_image` 工具
4. LLM 生成工具调用请求，包含优化后的 prompt

### 2.4 工具执行

**文件：`api/app/clients/tools/structured/ModelScopeQwenImage.js`**

```javascript
// 第 146-234 行：工具执行函数
const imageGenTool = tool(
  async ({ prompt, parameters = {}, model: overrideModel }, runnableConfig) => {
    // 1. 提交生成任务
    generationResponse = await submitGeneration({
      baseURL,
      apiKey,
      payload: { model, prompt: prompt.trim(), ...parameters },
      timeoutMs,
      signal,
    });

    // 2. 轮询任务状态
    taskResult = await pollForResult({
      baseURL,
      apiKey,
      taskId: generationResponse.task_id,
      // ...
    });

    // 3. 获取图片 URL
    const imageUrl = resolveImageUrl(taskResult.output_images[0]);

    // 4. 下载图片并转换为 base64
    const { base64: base64Image, contentType } = await fetchBase64(imageUrl, signal, timeoutMs);

    // 5. 返回 content_and_artifact 格式
    const file_ids = [v4()];
    const content = [{
      type: ContentTypes.IMAGE_URL,
      image_url: {
        url: `data:${contentType};base64,${base64Image}`,
      },
    }];
    const textResponse = [{
      type: ContentTypes.TEXT,
      text: displayMessage + `\n\ngenerated_image_id: "${file_ids[0]}"`,
    }];
    
    return [textResponse, { content, file_ids }];  // 返回两部分
  },
  toolkit.modelscope_qwen_image,
);
```

**返回格式说明：**
- `[textResponse, { content, file_ids }]` 是 `content_and_artifact` 格式
- 第一部分（`textResponse`）：文本消息，LLM 会看到这个
- 第二部分（`{ content, file_ids }`）：图片数据，用于前端显示

---

## 三、图片返回和显示流程

### 3.1 工具结果处理

**文件：`api/server/controllers/agents/callbacks.js`**

当工具执行完成后，会触发 `TOOL_END` 事件，调用 `createToolEndCallback`：

```javascript
// 第 277-408 行：createToolEndCallback
function createToolEndCallback({ req, res, artifactPromises }) {
  return async (data, metadata) => {
    const output = data?.output;
    
    // 检查是否有 artifact
    if (!output.artifact) {
      return;
    }

    // 处理 content_and_artifact 格式的图片
    if (output.artifact.content) {
      const content = output.artifact.content;
      for (let i = 0; i < content.length; i++) {
        const part = content[i];
        if (part.type !== 'image_url') {
          continue;
        }
        
        const { url } = part.image_url;  // data:image/jpeg;base64,...
        const file_id = output.artifact.file_ids?.[i];
        
        // 保存图片
        artifactPromises.push(
          (async () => {
            const file = await saveBase64Image(url, {
              req,
              file_id,
              filename: `${output.name}_${output.tool_call_id}_img_${nanoid()}`,
              endpoint: metadata.provider,
              context: FileContext.image_generation,
            });
            
            const fileMetadata = {
              ...file,
              messageId: metadata.run_id,
              toolCallId: output.tool_call_id,
              conversationId: metadata.thread_id,
            };
            
            // 通过 SSE 发送给前端
            if (!res.headersSent) {
              return fileMetadata;
            }
            res.write(`event: attachment\ndata: ${JSON.stringify(fileMetadata)}\n\n`);
            return fileMetadata;
          })()
        );
      }
    }
  };
}
```

**流程：**
1. 检测到 `output.artifact.content` 存在
2. 遍历 `content` 数组，找到 `type === 'image_url'` 的项
3. 提取 base64 图片数据（`data:image/jpeg;base64,...`）
4. 调用 `saveBase64Image` 保存图片到服务器
5. 生成文件元数据（包含 file_id、messageId 等）
6. 通过 Server-Sent Events (SSE) 发送给前端

### 3.2 前端显示

**前端接收到 SSE 事件：**
- 事件类型：`attachment`
- 数据：包含图片文件元数据的 JSON

**前端处理：**
1. 解析附件数据
2. 根据 `file_id` 获取图片 URL
3. 在消息中渲染图片组件
4. 用户可以看到生成的图片

### 3.3 消息格式

**最终返回给 LLM 的消息：**
```javascript
// formatMessages.js 第 203-210 行
messages.push(
  new ToolMessage({
    tool_call_id: tool_call.id,
    name: tool_call.name,
    content: output || '',  // 这里是 textResponse 的内容
  }),
);
```

LLM 看到的是文本消息（`displayMessage`），而不是图片数据。图片通过 artifact 单独处理。

---

## 四、完整流程图

```
┌─────────────────┐
│   用户输入中文    │
│   "帮我生成..."   │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  formatMessages  │  格式化消息为 LangChain 格式
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  LLM 分析请求    │  读取工具描述和 schema
│  优化 Prompt     │  翻译 + 增强细节
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  决定调用工具     │  modelscope_qwen_image
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  工具执行        │
│  1. 提交任务     │
│  2. 轮询状态     │
│  3. 下载图片     │
│  4. 转 base64    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  返回结果        │
│  [text, artifact]│
└────────┬────────┘
         │
         ├─────────────────┐
         │                 │
         ▼                 ▼
┌─────────────────┐  ┌─────────────────┐
│  ToolMessage    │  │  createToolEnd   │
│  (给 LLM)       │  │  Callback        │
└─────────────────┘  │  保存图片        │
                     │  发送 SSE        │
                     └────────┬─────────┘
                               │
                               ▼
                        ┌─────────────────┐
                        │   前端显示图片   │
                        └─────────────────┘
```

---

## 五、关键代码位置总结

| 功能 | 文件 | 关键行数 |
|------|------|---------|
| 工具定义 | `api/app/clients/tools/structured/ModelScopeQwenImage.js` | 14-39, 146-234 |
| 工具加载 | `api/app/clients/tools/util/handleTools.js` | 222-230 |
| 消息格式化 | `api/app/clients/prompts/formatMessages.js` | 141-238 |
| 智能体运行 | `api/server/controllers/agents/client.js` | 848-978 |
| 工具结果处理 | `api/server/controllers/agents/callbacks.js` | 277-408 |

---

## 六、总结

1. **提问优化**：由 LLM 根据工具描述和 schema 自动完成，不是代码层面的处理
2. **工具调用**：通过 LangChain Agent 框架，LLM 决定何时调用工具
3. **图片返回**：使用 `content_and_artifact` 格式，文本给 LLM，图片通过 artifact 单独处理
4. **前端显示**：通过 SSE 事件流实时发送图片元数据，前端渲染图片组件

整个流程充分利用了 LangChain 的 Agent 框架和工具调用机制，实现了智能的图片生成功能。





